ALSO SEE sourcemedia/notes/taxonomy-opportunities-and-pitfalls.txt

In The Necessity of Experience, one of the masterpieces of ecological psychology, Ed Reed ruminates that maybe our optimism that computers are becoming ever more like humans is misguided, maybe what's really happening is that humans are becoming ever more like machines, our education and work ever more based on rules and procedures. Think about how we search and read on the internet: we absorb huge amount of information by scanning and skimming, looking for keywords that might interest us, every story by every author interchangeable as long as it provides us with the required information, and only rarely do we still truly engage with the media in front of us.

It's a bit dark, Reed's vision, but how else can you explain why so many news organizations think it's perfectly okay to automate their twitter feed, why The Guardian has over three million mostly automated artist pages and why we don't revolt against tag and archive pages on just about every news site being endless list after list after list with no context? We're slowly training our readers to use news sites like a computer would.

I still agree with a lot I wrote two years ago information architecture for news website, but one area where I now feel I've been lured in were all the automated timelines and maps and topic pages I talked about, all driven by metadata. I told you how great those would be. And the fact is, they would make for a better news site than most of what's out there, but that's only because we've set our standards so low, because some news sites look like sheets of data interspersed with flickering ads.

It seems I'm not the only one lately who's realized that, wait a minute, why are we happy with this half-assed stuff? Last year's redesign of EveryBlock turned it from a big  dataset into a platform that actually brings neighbors together to discuss issues in their neighborhood and share experiences and advice. Why? Because although EveryBlock has always been a very exciting example of the "new journalism" for media watchers, it was an utterly boring piece of crap for the people it was actually meant for, who would at most check the news feed every once in a while and maybe, out of curiosity, check out the food safety records of their favorite restaurant.

Now, it's not that metadata annotations can't get you anywhere. They can get you a long way. It's that you can use the time you spend on annotation in so many other ways, notably: making (hand-crafted and hand-aggregated) specials, explainers, wiki pages and background stories.

Pick your battles and create less content that's really great. It's not because, as Shirky says, the problem isn't information overload but filter failure, that we're all supposed to produce more content and not care about the quality anymore.

---------

This is one of my guiding principles for the work I do at SourceMedia: metadata in service of great journalism, not as an excuse to not have to do any. Get yerself a content strategy.

---------

* In some ways, my thoughts haven't changed at all in the last two years: I still think special-purpose apps modeled around the problem they're trying to solve are, in many cases, superior to CMSes to aid in news reporting. I'll still advocate for the usefulness of metadata and structured content and complain about how wildly we underestimate what you can do when you go beyond big blobs of text. Where I've changed is that I no longer think metadata and taxonomies should get a free pass: they're just as much a part of creating a good experience, and there's really no point in using generic one-size-fits-all metadata. This is especially true for topics — even the most meticulous topical categorization doesn't really, by itself, support any interesting flows for users. The chief use for categories is and remains to populate section pages and to give people a general sense of what the hell it is they're reading — beyond that, I've never ever seen an experience that I particularly like.
I still think links to wiki pages about persons, organizations and events are a good idea, but whether those are codified as metadata or are just links within text is not something that really matters.
* libraries have (and need!) a one-size-fits-all catalogue: the very same bits of metadata for each and every book, magazine, whatever
* online, you don't really need this
- leads to halfway-there products that look robotic, no content strategy
- topics/categories are too fluid anyway to matter
- if you just invest in search (and it's disappointing how few news orgs do) then findability can increase to about the same level that you get with tags, sometimes even better (due to synonym awareness etc.), but without any effort in annotating.
- It's true, only manual metadata annotation can truly surface *every* story about a topic, person or organization predictably. But the happy fact is that only researchers need this kind of exhaustivity, whereas for most readers a good selection, preferably with explanatory notes or as part of a narrative, is what leads to truly engaging "topic pages".
- Instead, we should take Matt Waite's approach and create apps for every kind of news we publish, so that we have the precise structure we need. E.g. for fact-checking you'd want to reference a politician, the party he or she belongs to, the statement made, supporting facts and so on. For recipes it's the cuisine, time to cook, how expensive it is, et cetera. For news about local politics, it might be about issues (problems and how our politicians and local groups are solving them) and locations (is this in my neighborhood?). For culture, links to venues are important (and what can drive an events calendar, not just the reporting). And so on. _That's_ the valuable stuff. Generic metadata is what you do (a) for all the really basic stuff (this is the title, this is the author, this is the publication date) and (b) when you have absolutely no alternative, yet are absolutely convinced you need some form of metadata anyway.

---

How this has affected or will affect my work: 

* Metadata that makes sense for the app, as in the Cedar Rapids Shuffle: geolocation, bundling of content in issues, adding in context through linkups with wiki pages. (But those wiki pages don't contain twenty data points for every person, it's just text, because we don't need and will likely never need that data anyway.)
* Renewed focus on search, because a lot of my early focus on topical metadata stems from my belief that search was/is an awful way to find things on news sites (also an example of http/html as a universal api / interop layer)
* A little bit of planning ahead is good, a lot of it leads to trouble. If after a while we find out that we're storing too little structured information about our stories or the people in them, no worries, we can catch up afterwards. The added cost of having to go back and change stuff around is offset by the fact that we don't have to do all sorts of operations just because they *may* one day prove useful for some undefined purpose.
* Stories over structure: advocating for wiki content about persons, organizations and events. (But it's the content that matters, not the metadata to link stories to persons, that's the easy/boring part and something hyperlinks can take care of anyway.)
* It's all about flows (see my story-wiki linkup prototype)