* Don't try to quantify what isn't quantifiable (but you can still measure and find appropriate heuristics!) e.g. for a crowdsourcing project you can make it a habit to always evaluate how well it went and try to distill lessons out of that experience. The fact that you're doing a debrief at all is much more valuable than having hard numbers that can tell you your effort was an 82 on the crowdsourcing scale.


* While I'm really enamored with the idea of measuring impact, I don't think it's a good idea to try and quantify that. But maybe we can combine quantitative metrics that measure mindshare/measurability with heuristics to determine qualitatively how well we think a story did, e.g. with a standardized five-question checklist or questionnaire (Are you happy with the attention this story received? Do you think most people understood what it meant and why this is important? Should we follow up?) Doesn't matter that those things are a bit vague sometimes. "Measure things to improve them" still applies, but there is absolutely no reason to try and reduce those measurement to hard numbers that only tell half the story anyway. So maybe we should mix those together?
* As Daniel Bachhuber suggested, maybe you can poll your readers and ask them simple questions sometimes, do determine how many people in your audience know the basics of a certain issue. (Or, as Daniel suggested, use it to determine whether people see or don't see intro grafs to a story.)



* Writers should be able to compare their performance to their peers. I don't like the idea of editors harassing reporters when their stats aren't up to snuff, but maybe if a reporter sees that he's doing very poorly on social media compared to his colleagues, that might be something that reporter will think about and do something about.


